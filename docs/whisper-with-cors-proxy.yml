version: '3.8'

services:
  # Whisper-ASR service (no changes)
  whisper-asr-gpu:
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    container_name: whisper-asr-gpu

    runtime: nvidia

    # Don't expose port 9000 directly - only through Caddy
    expose:
      - "9000"

    environment:
      - ASR_ENGINE=faster_whisper
      - ASR_MODEL=medium
      - ASR_DEVICE=cuda
      - COMPUTE_TYPE=float16
      - MODEL_IDLE_TIMEOUT=600
      - LOG_LEVEL=DEBUG

    volumes:
      - ./whisper-gpu-cache:/root/.cache

    restart: unless-stopped

    networks:
      - whisper-net

  # nginx reverse proxy to add CORS headers
  nginx-cors:
    image: nginx:alpine
    container_name: whisper-nginx-cors

    ports:
      - "9000:9000"  # Expose through nginx instead

    # Create nginx config inline using command
    command: >
      sh -c "echo '
      server {
          listen 9000;
          location / {
              # CORS headers
              add_header Access-Control-Allow-Origin * always;
              add_header Access-Control-Allow-Methods \"GET, POST, OPTIONS\" always;
              add_header Access-Control-Allow-Headers \"*\" always;
              add_header Access-Control-Max-Age 3600 always;

              # Handle preflight
              if ($$request_method = OPTIONS) {
                  return 204;
              }

              # Proxy to Whisper-ASR
              proxy_pass http://whisper-asr-gpu:9000;
              proxy_set_header Host $$host;
              proxy_set_header X-Real-IP $$remote_addr;
          }
      }
      ' > /etc/nginx/conf.d/default.conf && nginx -g 'daemon off;'"

    restart: unless-stopped

    networks:
      - whisper-net

    depends_on:
      - whisper-asr-gpu

networks:
  whisper-net:
    driver: bridge
